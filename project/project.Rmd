---
title: "Project Days"
author: "Matthew Workentine"
date: '2018-01-02'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries

```{r}
library(tidyverse)
```

## Introduction

The data we're going to work with comes from a yeast microarray experiment [(Brauer, 2008)](http://www.molbiolcell.org/content/19/1/352.abstract) where the authors measured gene expression in 36 chemostat cultures where growth was limited by one of six nutrients (glucose, ammonium, sulfate, phosphate, uracil, or leucine) at 3 different growth rates.   

The R world is full of niche tools designed for a specific problem or data type.  This is particularly true for Bioconductor and genomics analysis.  RNA-seq is a good example where all data import, analysis, and even plotting is done with custom packages and functions designed for gene expression data. Analysis of microbiome data with phyloseq is another example.  Now this is not a bad thing and can enable simple, rapid analysis.  Yet the point of learning a programming language like R is so you can take back control of your analysis and put the tools to work for your specific problem.  

For this project we're going to take some genomic data and pull it out of the context that it's usually analyzed in.  Bioconductor has a plethora of tools for analyzing microarray data and the `limma` package is by far the most comprehensive and useful.  However, for our project we're going to take microarray data that has already been processed and instead use it with data analysis tools that we've been learning.  

The take-away from this project to make the tools work for you instead of you working for them.  Data, genomic or not, is still data and we can use the tools available to us in R to gain valuable insights.


## Task 1: Data import and examination

The first task of almost all analysis is to get the data into R and spend a little time understanding it's structure.  Although you may be tempted to rush into an analysis it pays to take a bit of time to understand what you are working with and do some cleaning before you dive in too deep.  This is important help you avoid costly mistakes and wasted time downstream.  

The data file you'll be using is `Brauer2008_DataSet1.tds` and although it is pre-processed it will still need some work to get it ready to use.

Your goal is get the data loaded into R and answer the following questions:

* How many rows and columns are there?
* What do the rows and columns represent?
* On first glimpse do the column datatypes look correct?
* What about column names? 
* Is this data tidy?  Why or why not?  

As you look through the data start thinking about what steps you'll need to get it into a workable state.  

```{r}

raw = read_tsv("data/Brauer2008_DataSet1.tds")
head(raw)
```

## Task 2: Data Tidying

Never underestimate the amount of time and effort it will take to tame a wild dataset into something useable.  Even if someone has already processed and "cleaned" the data before you (such as our current dataset) it is likely that you will need to spend some time fiddling with it for your particular needs (or for a particular function you want to use).  

You've learned about the tidy data concepts, now it's time to put them into practice. The first and most important step is decide what, if any tidying needs to be done. Recall that:

1. Each variable forms a column.
2. Each observation forms a row.
2. Each type of observational unit forms a table.

Questions to answer:

* Which column contains multiple variables?  Split it up so each column represents a single variable.
* The `GWEIGHT`, `GID`, and `YORF` columns we also won't need so you can get rid of those.
* What's wrong with the column names?  How can you fix that?
* Check again: do you have any columns that have multipe variables?  Be sure to fix any before you move on.

Try to code all the cleaning steps as a single pipeline.  The `separate()` and `gather()` functions from the tidyr package are a good place to start to accomplish these tasks.  

**Bonus:** Your cleaning steps may have left some variables with extra whitespace at the end.  Using `dplyr::mutate_each()` and a certain function from the `stringr` package see if you can clean these up.

```{r}
raw %>% 
  separate(NAME, c("gene_name", "BP", "MP", "gene_id", "number"), sep = "\\|\\|") %>% 
  

```


